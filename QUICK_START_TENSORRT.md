# TensorRT HÄ±zlÄ± BaÅŸlangÄ±Ã§ Rehberi

Bu rehber, projedeki TensorRT backend'ini hÄ±zlÄ±ca kullanmaya baÅŸlamanÄ±z iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.

## âš¡ 5 Dakikada TensorRT

### AdÄ±m 1: Kurulum

```bash
# TensorRT paketlerini yÃ¼kle
pip install torch2trt nvidia-tensorrt

# Veya tÃ¼m gereksinimleri yÃ¼kle
pip install -r requirements.txt
```

### AdÄ±m 2: Ä°lk Ã‡alÄ±ÅŸtÄ±rma

```bash
# Input klasÃ¶rÃ¼ne ses dosyanÄ±zÄ± koyun
cp your_audio.wav input/

# TensorRT ile iÅŸleyin
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16 \
    --use_tensorrt_cache
```

### AdÄ±m 3: Ã‡Ä±ktÄ±yÄ± Kontrol Edin

```bash
ls output/
# Ã‡Ä±ktÄ±: your_audio_Vocals_ModelName.wav
#        your_audio_Instrumental_ModelName.wav
```

## ğŸ¯ HÄ±zlÄ± Komutlar

### Temel KullanÄ±m

```bash
# FP16 precision ile (Ã¶nerilen)
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16 \
    --use_tensorrt_cache
```

### FP32 Precision

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp32
```

### Instrumental Ã‡Ä±kart

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --extract_instrumental \
    --tensorrt_precision fp16
```

## ğŸ“Š Benchmark

### HÄ±zlÄ± Performans Testi

```bash
python benchmark_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --num_iterations 50
```

### DetaylÄ± Benchmark

```bash
python benchmark_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --precision fp16 \
    --num_iterations 100 \
    --warmup_iterations 20
```

## ğŸ”¥ PopÃ¼ler Model Ã–rnekleri

### Vokal AyÄ±rma (MelBand-Roformer)

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/big_beta6x.yaml \
    --start_check_point ckpts/big_beta6x.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16 \
    --use_tensorrt_cache
```

### Vokal AyÄ±rma (BS-Roformer)

```bash
python inference_tensorrt.py \
    --model_type bs_roformer \
    --config_path ckpts/model_bs_roformer_ep_317_sdr_12.9755.yaml \
    --start_check_point ckpts/model_bs_roformer_ep_317_sdr_12.9755.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16
```

### 4-Stem AyÄ±rma (SCNet)

```bash
python inference_tensorrt.py \
    --model_type scnet \
    --config_path ckpts/config_musdb18_scnet.yaml \
    --start_check_point ckpts/scnet_checkpoint_musdb18.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16
```

## ğŸ¨ Gradio Web UI

### TensorRT ile Web UI

```bash
# Web UI'yi baÅŸlat
python main.py --method gradio --port 7860

# TarayÄ±cÄ±da aÃ§: http://localhost:7860
# "Use TensorRT" checkbox'Ä±nÄ± iÅŸaretle
```

## ğŸ’» Python API KullanÄ±mÄ±

### Basit Ã–rnek

```python
from tensorrt_backend import TensorRTBackend, load_model_from_checkpoint
from utils import get_model_from_config
import torch

# Model yÃ¼kle
model, config = get_model_from_config('mel_band_roformer', 'ckpts/config.yaml')
model = load_model_from_checkpoint('ckpts/model.ckpt', model, 'cuda:0')

# TensorRT backend
trt_backend = TensorRTBackend(device='cuda:0')
trt_backend.compile_model(
    model=model,
    input_shape=(1, 2, 352800),
    precision='fp16',
    use_cache=True
)

# Inference
audio = torch.randn(1, 2, 352800).cuda()
output = trt_backend(audio)
```

### DetaylÄ± Ã–rnekler

```bash
# Ã–rnekleri Ã§alÄ±ÅŸtÄ±r
python examples/tensorrt_example.py
```

## ğŸ“‹ Model Ä°ndirme

### Otomatik Ä°ndirme

Modeller ilk kullanÄ±mda otomatik olarak indirilir:

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/big_beta6x.yaml \
    --start_check_point ckpts/big_beta6x.ckpt \
    --input_folder input/ \
    --store_dir output/
```

### Manuel Ä°ndirme

```python
from model import download_file

# Model config
download_file('https://huggingface.co/.../config.yaml')

# Model checkpoint
download_file('https://huggingface.co/.../model.ckpt')
```

## âš™ï¸ KonfigÃ¼rasyon

### Chunk Size ve Overlap

```bash
# BÃ¼yÃ¼k chunk size (daha hÄ±zlÄ± ama daha fazla memory)
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --chunk_size 500000 \
    --overlap 2

# KÃ¼Ã§Ã¼k chunk size (daha yavaÅŸ ama daha az memory)
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --chunk_size 200000 \
    --overlap 4
```

### Batch Processing

```bash
# Birden fazla dosya iÅŸle
cp song1.wav input/
cp song2.wav input/
cp song3.wav input/

python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/
```

## ğŸ” Sorun Giderme

### TensorRT YÃ¼klenmedi

```bash
pip install torch2trt nvidia-tensorrt --force-reinstall
```

### CUDA HatasÄ±

```bash
# CUDA versiyonunu kontrol et
python -c "import torch; print(torch.version.cuda)"

# Uyumlu PyTorch yÃ¼kle
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### Memory HatasÄ±

```bash
# Chunk size'Ä± azalt
python inference_tensorrt.py ... --chunk_size 100000

# FP16 kullan
python inference_tensorrt.py ... --tensorrt_precision fp16
```

## ğŸ“ˆ Performans Ä°puÃ§larÄ±

### En HÄ±zlÄ± Ayarlar

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16 \
    --use_tensorrt_cache \
    --chunk_size 500000 \
    --overlap 2
```

### En YÃ¼ksek Kalite Ayarlar

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp32 \
    --chunk_size 300000 \
    --overlap 8 \
    --use_tta
```

## ğŸ“ Daha Fazla Bilgi

- [DetaylÄ± TensorRT DokÃ¼mantasyonu](README_TensorRT.md)
- [Kurulum Rehberi](INSTALL_TENSORRT.md)
- [Ã–rnek Kodlar](examples/tensorrt_example.py)
- [Ana DokÃ¼mantasyon](README_TR.md)

## ğŸ’¬ YardÄ±m

Sorun yaÅŸÄ±yorsanÄ±z:

1. `benchmark_tensorrt.py` ile test edin
2. [INSTALL_TENSORRT.md](INSTALL_TENSORRT.md) kurulum rehberini takip edin
3. GitHub Issues'da arama yapÄ±n
4. Yeni issue aÃ§Ä±n

---

**Ä°pucu:** Ä°lk Ã§alÄ±ÅŸtÄ±rmada TensorRT compilation ~1-5 dakika sÃ¼rer. Sonraki Ã§alÄ±ÅŸtÄ±rmalar Ã¶nbellekten yÃ¼klenir ve Ã§ok hÄ±zlÄ±dÄ±r!

**Ã–nemli:** `--use_tensorrt_cache` parametresini kullanmayÄ± unutmayÄ±n!
