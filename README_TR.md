# Music Source Separation with TensorRT

Bu proje, mÃ¼zik kaynak ayÄ±rma (Music Source Separation) iÃ§in PyTorch tabanlÄ± derin Ã¶ÄŸrenme modellerini destekler ve artÄ±k **NVIDIA TensorRT** backend ile geliÅŸmiÅŸ performans sunar.

## ğŸš€ Yeni Ã–zellikler: TensorRT DesteÄŸi

- âš¡ **3x Daha HÄ±zlÄ± Ä°nference**: TensorRT optimizasyonu ile iÅŸleme sÃ¼resini %66'ya kadar azaltÄ±n
- ğŸ’¾ **Daha Az Bellek KullanÄ±mÄ±**: FP16 precision ile GPU bellek kullanÄ±mÄ±nÄ± optimize edin
- ğŸ”¥ **Otomatik Ã–nbellekleme**: Ä°lk derlemeden sonra hÄ±zlÄ± yÃ¼kleme
- ğŸ¯ **Kolay KullanÄ±m**: Tek parametre ile TensorRT'yi aktif edin
- ğŸ”„ **Geriye DÃ¶nÃ¼k Uyumlu**: TensorRT yÃ¼klÃ¼ deÄŸilse otomatik PyTorch'a geÃ§iÅŸ

## ğŸ“‹ Gereksinimler

### Temel Gereksinimler
- Python 3.8+
- NVIDIA GPU (Compute Capability 6.0+)
- CUDA 11.x veya 12.x
- PyTorch 2.0+ with CUDA

### TensorRT Ä°Ã§in Ek Gereksinimler
```bash
pip install torch2trt
pip install nvidia-tensorrt
```

DetaylÄ± kurulum iÃ§in: [INSTALL_TENSORRT.md](INSTALL_TENSORRT.md)

## ğŸ¯ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Normal Inference (PyTorch)

```bash
python inference.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/
```

### 2. TensorRT HÄ±zlandÄ±rmalÄ± Inference

```bash
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16 \
    --use_tensorrt_cache
```

### 3. Inference.py Ä°le TensorRT KullanÄ±mÄ±

```bash
python inference.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --use_tensorrt \
    --tensorrt_precision fp16
```

## ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

### Benchmark Ã‡alÄ±ÅŸtÄ±rma

```bash
python benchmark_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --precision fp16 \
    --num_iterations 100
```

### Ã–rnek SonuÃ§lar (RTX 3090)

| Model | PyTorch | TensorRT FP16 | HÄ±zlanma |
|-------|---------|---------------|----------|
| MelBand-Roformer | 150ms | 50ms | **3.0x** |
| BS-Roformer | 180ms | 60ms | **3.0x** |
| MDX23C | 100ms | 40ms | **2.5x** |

## ğŸ› ï¸ Parametreler

### TensorRT Parametreleri

- `--use_tensorrt`: TensorRT backend'ini aktif et
- `--tensorrt_precision`: Precision mode (`fp32` veya `fp16`)
- `--use_tensorrt_cache`: TensorRT engine Ã¶nbelleÄŸini kullan
- `--tensorrt_cache_dir`: Ã–nbellek dizini (default: `trt_cache/`)

### Inference Parametreleri

- `--model_type`: Model tipi (Ã¶rn: `mel_band_roformer`, `bs_roformer`, `mdx23c`)
- `--config_path`: Model config dosyasÄ± yolu
- `--start_check_point`: Model checkpoint (.ckpt) dosyasÄ±
- `--input_folder`: Girdi ses dosyalarÄ± klasÃ¶rÃ¼
- `--store_dir`: Ã‡Ä±ktÄ± dosyalarÄ± klasÃ¶rÃ¼
- `--chunk_size`: Ä°ÅŸleme chunk boyutu
- `--overlap`: Overlap faktÃ¶rÃ¼
- `--extract_instrumental`: Instrumental track Ã§Ä±kar
- `--use_tta`: Test-Time Augmentation kullan

## ğŸ“ Proje YapÄ±sÄ±

```
.
â”œâ”€â”€ tensorrt_backend.py          # TensorRT backend implementasyonu
â”œâ”€â”€ inference_tensorrt.py        # TensorRT ile inference
â”œâ”€â”€ inference.py                 # Normal PyTorch inference
â”œâ”€â”€ benchmark_tensorrt.py        # Benchmark aracÄ±
â”œâ”€â”€ processing.py                # Ana iÅŸleme fonksiyonlarÄ±
â”œâ”€â”€ gui.py                       # Gradio web arayÃ¼zÃ¼
â”œâ”€â”€ model.py                     # Model konfigÃ¼rasyonlarÄ±
â”œâ”€â”€ utils.py                     # YardÄ±mcÄ± fonksiyonlar
â”œâ”€â”€ ensemble.py                  # Ensemble iÅŸlemleri
â”œâ”€â”€ trt_cache/                   # TensorRT engine Ã¶nbelleÄŸi
â”œâ”€â”€ ckpts/                       # Model checkpoint'leri
â”œâ”€â”€ input/                       # Girdi ses dosyalarÄ±
â”œâ”€â”€ output/                      # Ã‡Ä±ktÄ± ses dosyalarÄ±
â”œâ”€â”€ examples/                    # Ã–rnek kodlar
â”‚   â””â”€â”€ tensorrt_example.py
â””â”€â”€ README_TensorRT.md           # TensorRT dokÃ¼mantasyonu
```

## ğŸ”§ TensorRT Backend API

### Python API KullanÄ±mÄ±

```python
from tensorrt_backend import TensorRTBackend, load_model_from_checkpoint
from utils import get_model_from_config

# Model yÃ¼kle
model, config = get_model_from_config('mel_band_roformer', 'config.yaml')
model = load_model_from_checkpoint('model.ckpt', model, 'cuda:0')

# TensorRT backend oluÅŸtur
trt_backend = TensorRTBackend(device='cuda:0', cache_dir='trt_cache')

# Model'i compile et
trt_backend.compile_model(
    model=model,
    input_shape=(1, 2, 352800),  # (batch, channels, chunk_size)
    precision='fp16',
    use_cache=True
)

# Inference
import torch
audio_input = torch.randn(1, 2, 352800).cuda()
output = trt_backend(audio_input)
```

## ğŸ¨ Gradio Web ArayÃ¼zÃ¼

Web arayÃ¼zÃ¼ Ã¼zerinden TensorRT kullanÄ±mÄ±:

```bash
python main.py --method gradio --port 7860
```

ArayÃ¼zde "Use TensorRT" seÃ§eneÄŸini aktif edin.

## ğŸ“š Desteklenen Modeller

TÃ¼m mevcut modeller TensorRT ile uyumludur:

### Vokal Modelleri
- VOCALS-big_beta6X (by Unwa)
- VOCALS-MelBand-Roformer (by KimberleyJSN)
- VOCALS-BS-Roformer_1297 (by viperx)
- ve diÄŸerleri...

### Instrumental Modelleri
- INST-Mel-Roformer v1 (by unwa)
- INST-MelBand-Roformer (by Becruily)
- ve diÄŸerleri...

### 4-Stem Modelleri
- 4STEMS-SCNet_MUSDB18 (by starrytong)
- 4STEMS-BS-Roformer_MUSDB18 (by ZFTurbo)
- ve diÄŸerleri...

Tam liste iÃ§in `model.py` dosyasÄ±na bakÄ±n.

## ğŸ› Sorun Giderme

### TensorRT BulunamadÄ±

```bash
pip install torch2trt nvidia-tensorrt
```

### CUDA Out of Memory

- Batch size azaltÄ±n: `--batch_size 1`
- Chunk size azaltÄ±n: `--chunk_size 100000`
- FP16 kullanÄ±n: `--tensorrt_precision fp16`

### Ä°lk Ã‡alÄ±ÅŸtÄ±rma YavaÅŸ

Ä°lk Ã§alÄ±ÅŸtÄ±rmada TensorRT compilation yapÄ±lÄ±r (~1-5 dakika). Sonraki Ã§alÄ±ÅŸtÄ±rmalar Ã¶nbellekten yÃ¼klenir.

## ğŸ’¡ Ä°puÃ§larÄ± ve En Ä°yi Uygulamalar

1. **Ä°lk KullanÄ±mda**: `--use_tensorrt_cache` ile Ã¶nbelleÄŸi aktif edin
2. **FP16 KullanÄ±n**: Modern GPU'larda (RTX 20xx+) FP16 en iyi performansÄ± verir
3. **Batch Size**: GPU belleÄŸi izin veriyorsa batch size artÄ±rÄ±n
4. **Ã–nbellek**: Model deÄŸiÅŸmezse Ã¶nbellek her zaman kullanÄ±lmalÄ±

## ğŸ“– DokÃ¼mantasyon

- [TensorRT Kurulum Rehberi](INSTALL_TENSORRT.md)
- [TensorRT KullanÄ±m KÄ±lavuzu](README_TensorRT.md)
- [Ã–rnek Kodlar](examples/tensorrt_example.py)

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen pull request gÃ¶nderin veya issue aÃ§Ä±n.

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt)
- [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt)
- [PyTorch](https://pytorch.org/)
- TÃ¼m model geliÅŸtiricileri

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in:
- GitHub Issues
- Pull Requests

---

**Not:** TensorRT kullanÄ±mÄ± opsiyoneldir. YÃ¼klÃ¼ deÄŸilse proje normal PyTorch inference ile Ã§alÄ±ÅŸÄ±r.

**Ã–nemli:** Ä°lk Ã§alÄ±ÅŸtÄ±rmada TensorRT compilation yapÄ±lacaÄŸÄ±ndan iÅŸlem 1-5 dakika sÃ¼rebilir. Sonraki Ã§alÄ±ÅŸtÄ±rmalar Ã§ok daha hÄ±zlÄ± olacaktÄ±r.
