# TensorRT Kurulum Rehberi

Bu rehber, projedeki TensorRT backend'ini kurmanÄ±z iÃ§in adÄ±m adÄ±m talimatlar iÃ§erir.

## ğŸ¯ Gereksinimler

- NVIDIA GPU (Compute Capability 6.0+)
- Windows 10/11 veya Linux
- Python 3.8+
- CUDA 11.x veya 12.x
- PyTorch with CUDA support

## ğŸ“‹ AdÄ±m AdÄ±m Kurulum

### 1. CUDA Toolkit KontrolÃ¼

CUDA'nÄ±n yÃ¼klÃ¼ olduÄŸunu kontrol edin:

```bash
nvcc --version
```

EÄŸer CUDA yÃ¼klÃ¼ deÄŸilse:
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) indirin ve kurun

### 2. PyTorch CUDA KontrolÃ¼

```bash
python -c "import torch; print(torch.cuda.is_available())"
```

Ã‡Ä±ktÄ± `True` olmalÄ±dÄ±r. EÄŸer `False` ise, PyTorch'u CUDA desteÄŸi ile yeniden kurun:

```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 3. TensorRT Kurulumu

#### YÃ¶ntem 1: pip ile (Ã–nerilen)

```bash
pip install nvidia-tensorrt
pip install torch2trt
```

#### YÃ¶ntem 2: Manuel Kurulum

1. [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt) sayfasÄ±ndan indirin
2. Ä°ndirilen dosyayÄ± extract edin
3. Python wheel'i kurun:

```bash
cd TensorRT-x.x.x.x/python
pip install tensorrt-*-cp3x-none-win_amd64.whl
```

### 4. torch2trt Kurulumu

```bash
# GitHub'dan klon
git clone https://github.com/NVIDIA-AI-IOT/torch2trt
cd torch2trt
python setup.py install
```

### 5. Kurulum Testi

```bash
python -c "from tensorrt_backend import is_tensorrt_available; print('TensorRT Available:', is_tensorrt_available())"
```

Ã‡Ä±ktÄ± `True` olmalÄ±dÄ±r.

## ğŸ”§ Kurulum SorunlarÄ±

### ImportError: No module named 'tensorrt'

**Ã‡Ã¶zÃ¼m:**
```bash
pip install nvidia-tensorrt --force-reinstall
```

### torch2trt ImportError

**Ã‡Ã¶zÃ¼m:**
```bash
# Ã–nce torch2trt'yi kaldÄ±rÄ±n
pip uninstall torch2trt

# GitHub'dan yeniden kurun
git clone https://github.com/NVIDIA-AI-IOT/torch2trt
cd torch2trt
python setup.py install
```

### CUDA Version Mismatch

TensorRT ve PyTorch CUDA versiyonlarÄ± uyumlu olmalÄ±dÄ±r:

```bash
# PyTorch CUDA versiyonunu kontrol edin
python -c "import torch; print(torch.version.cuda)"

# EÄŸer uyumsuzluk varsa, uyumlu PyTorch kurun
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### Windows'ta DLL Eksik HatasÄ±

`cudnn64_8.dll` veya `nvinfer.dll` bulunamÄ±yorsa:

1. CUDA Toolkit'in `bin` klasÃ¶rÃ¼nÃ¼ PATH'e ekleyin:
```
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\bin
```

2. TensorRT'nin `lib` klasÃ¶rÃ¼nÃ¼ PATH'e ekleyin:
```
C:\TensorRT-x.x.x.x\lib
```

### Linux'ta Permission Error

```bash
sudo pip install nvidia-tensorrt torch2trt
```

## âœ… Kurulum DoÄŸrulama

### Test Script Ã‡alÄ±ÅŸtÄ±rma

Proje klasÃ¶rÃ¼nde:

```bash
python benchmark_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --num_iterations 10
```

Bu komut:
- âœ“ Model yÃ¼kleme
- âœ“ TensorRT compilation
- âœ“ Inference
- âœ“ Benchmark

adÄ±mlarÄ±nÄ± test eder.

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

TensorRT kurulumundan sonra:

```bash
# TensorRT ile inference
python inference_tensorrt.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/ \
    --tensorrt_precision fp16 \
    --use_tensorrt_cache
```

## ğŸ“¦ TÃ¼m Gereksinimler

```bash
# TÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± kur
pip install -r requirements.txt

# TensorRT paketlerini manuel kur
pip install nvidia-tensorrt
pip install torch2trt
```

## ğŸ” Sistem Bilgilerini Kontrol Etme

```python
import torch
print(f"PyTorch Version: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Version: {torch.version.cuda}")
print(f"GPU: {torch.cuda.get_device_name(0)}")

try:
    import tensorrt as trt
    print(f"TensorRT Version: {trt.__version__}")
except ImportError:
    print("TensorRT: Not installed")

try:
    from torch2trt import torch2trt
    print("torch2trt: Installed")
except ImportError:
    print("torch2trt: Not installed")
```

## ğŸ’¡ Ã–nerilen KonfigÃ¼rasyon

### Windows 10/11

- CUDA 11.8
- PyTorch 2.0+ with CUDA 11.8
- TensorRT 8.6+
- torch2trt (latest from GitHub)

### Linux (Ubuntu 20.04/22.04)

- CUDA 11.8 or 12.1
- PyTorch 2.0+ with CUDA
- TensorRT 8.6+
- torch2trt (latest from GitHub)

## ğŸ“ Alternatif: TensorRT Olmadan KullanÄ±m

TensorRT kurulumu opsiyoneldir. TensorRT yÃ¼klÃ¼ deÄŸilse:

```bash
# Normal PyTorch inference
python inference.py \
    --model_type mel_band_roformer \
    --config_path ckpts/config.yaml \
    --start_check_point ckpts/model.ckpt \
    --input_folder input/ \
    --store_dir output/
```

Proje otomatik olarak PyTorch inference'a geri dÃ¶ner.

## ğŸ“ YardÄ±m

Kurulum sorunlarÄ± iÃ§in:
1. GPU ve CUDA versiyonunuzu kontrol edin
2. PyTorch CUDA desteÄŸini doÄŸrulayÄ±n
3. TensorRT versiyonunun CUDA ile uyumlu olduÄŸunu kontrol edin
4. GitHub Issues bÃ¶lÃ¼mÃ¼nde arama yapÄ±n

---

**Son GÃ¼ncelleme:** 2024
